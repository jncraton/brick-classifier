<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title></title>
    <style>
    body {
      max-width:800px;
      margin: 0 auto;
      text-align: center;
      padding-top: 5em;
    }

    * {
      font-size: 24px;
    }

    canvas {
      width: 224px;
      display: inline-block;
    }

    label {
      display:inline-block;
      border:1px solid #999;
      padding:5px;
      background:#9c9;
      margin:1em;
    }
    </style>
  </head>

  <body>
    <label>Capture
    <input style="display:none" type="file" id="imageLoader" name="imageLoader" accept="image/*" capture="camera" /></label>
    <br>
    <canvas id="imageCanvas"></canvas>
    <ol id=results></ol>
    
    <!-- Load ONNX.js -->
    <script src="https://cdn.jsdelivr.net/npm/onnxjs/dist/onnx.min.js"></script>
    <script src="./ndarray.js"></script>
    <script src="./image-loader.js"></script>

    <!-- console for mobile
    <script src="//cdn.jsdelivr.net/npm/eruda"></script>
    <script>eruda.init();</script>
    -->
    
    <!-- Code that consume ONNX.js -->
    <script>
      const class_names = ["11211", "11477", "15068", "15573", "15712", "2357", "2412b", "2420", "2431", "2432", "2445", "2456", "2540", "2654", "2780", "2877", "3001", "3002", "3003", "3004", "3005", "3008", "3009", "3010", "3020", "3021", "3022", "3023", "3024", "3031", "3032", "3034", "3035", "3036", "30374", "3039", "3040b", "30414", "3062b", "3068b", "3069b", "3070b", "32013", "32028", "32062", "32123b", "3298", "3460", "3622", "3623", "3660", "3665", "3666", "3673", "3700", "3701", "3705", "3706", "3710", "3713", "3749", "3795", "3829c01", "3832", "3937", "3941", "3958", "4032a", "4070", "4081b", "4162", "4274", "4286", "43093", "44728", "4477", "4519", "4740", "48336", "50950", "54200", "59443", "59900", "60478", "60897", "6091", "6141", "63864", "63868", "6541", "6558", "6636", "85984", "87079", "87087", "87580", "93273", "98138", "99780"]

      var imageLoader = document.getElementById('imageLoader');
          imageLoader.addEventListener('change', handleImage, false);
      var canvas = document.getElementById('imageCanvas');
      var ctx = canvas.getContext('2d');

      function handleImage(e){
          document.getElementById('results').innerHTML='Processing image...'
          var reader = new FileReader();
          reader.onload = function(event){
              var img = new Image();
              img.onload = function(){
                  // Crop to square
                  const short = Math.min(img.width, img.height)
                  const long = Math.max(img.width, img.height)
                  canvas.width = short;
                  canvas.height = short;
                  let xoffset = img.width < img.height ? 0 : -(long - short) / 2
                  let yoffset = img.height < img.width ? 0 : -(long - short) / 2
                  ctx.drawImage(img, xoffset, yoffset)
              }
              img.src = event.target.result;
              classify(event.target.result)
          }
          reader.readAsDataURL(e.target.files[0]);     
      }
    
      function preprocess(data, width, height) {
        const dataFromImage = ndarray(new Float32Array(data), [width, height, 4]);
        const dataProcessed = ndarray(new Float32Array(width * height * 3), [1, 3, height, width]);

        // Normalize 0-255 to (-1)-1
        ndarray.ops.divseq(dataFromImage, 128.0);
        ndarray.ops.subseq(dataFromImage, 1.0);

        // Realign imageData from [224*224*4] to the correct dimension [1*3*224*224].
        // TODO: This could use correct grayscale handling
        // This just uses color channel 3 for all colors
        ndarray.ops.assign(dataProcessed.pick(0, 0, null, null), dataFromImage.pick(null, null, 2));
        ndarray.ops.assign(dataProcessed.pick(0, 1, null, null), dataFromImage.pick(null, null, 2));
        ndarray.ops.assign(dataProcessed.pick(0, 2, null, null), dataFromImage.pick(null, null, 2));

        return dataProcessed.data;
      }

      function classify(img) {
        // create a session
        const myOnnxSession = new onnx.InferenceSession('wasm');
        // load the ONNX model file
        myOnnxSession.loadModel('./part-classifier.onnx').then(() => {
          // generate model input
          const imageLoader = new ImageLoader(224, 224);
          imageLoader.getImageData(img).then((imageData) => {
            const preprocessedData = preprocess(imageData.data, 224, 224);
            const inputTensor = new onnx.Tensor(preprocessedData, 'float32', [1, 3, 224, 224]);
            myOnnxSession.run([inputTensor]).then((output) => {
              const outputTensor = output.values().next().value;

              let results = class_names.map((name, i) => { 
                return [outputTensor.data[i], class_names[i]]
              })

              results.sort((a, b) => b[0] - a[0])

              const items = results.map(item => {
                return `<img src="https://cdn.rebrickable.com/media/thumbs/parts/ldraw/71/${item[1]}.png/72x72p.png" alt="${item[1]}" /> ${item[1]} (${item[0]})`
              })
              
              document.getElementById('results').innerHTML = '<li>' + items.join('<li>')
            });
          });
        });
      }
    </script>
  </body>
</html>
